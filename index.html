<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Friday</title>
<style>
  :root {
    --bg: #0f0f0f;
    --surface: #1a1a2e;
    --surface2: #16213e;
    --accent: #e94560;
    --accent2: #0f3460;
    --text: #eee;
    --text2: #999;
    --green: #00d97e;
    --radius: 12px;
  }
  * { box-sizing: border-box; margin: 0; padding: 0; }
  body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
    background: var(--bg);
    color: var(--text);
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    align-items: center;
  }
  header {
    padding: 24px;
    text-align: center;
  }
  header h1 { font-size: 1.5rem; font-weight: 600; }

  #status {
    color: var(--text2);
    font-size: 0.85rem;
    min-height: 20px;
    margin-bottom: 12px;
    transition: color 0.2s;
  }
  #status.active { color: var(--green); }
  #status.listening { color: var(--accent); }

  #chat {
    flex: 1;
    width: 100%;
    max-width: 640px;
    overflow-y: auto;
    padding: 0 16px 120px;
  }
  .msg {
    margin: 8px 0;
    padding: 12px 16px;
    border-radius: var(--radius);
    max-width: 85%;
    line-height: 1.5;
    font-size: 0.95rem;
    position: relative;
  }
  .msg.user {
    background: var(--accent2);
    margin-left: auto;
    border-bottom-right-radius: 4px;
  }
  .msg.assistant {
    background: var(--surface);
    margin-right: auto;
    border-bottom-left-radius: 4px;
  }
  .msg.streaming {
    border-left: 2px solid var(--accent);
  }
  .msg.streaming::after {
    content: '▋';
    animation: blink 1s infinite;
    color: var(--accent);
  }
  .msg.interrupted {
    opacity: 0.6;
    border-left: 2px solid var(--text2);
  }
  .msg.interrupted::after {
    content: ' [interrupted]';
    color: var(--text2);
    font-size: 0.75rem;
  }
  @keyframes blink {
    0%, 50% { opacity: 1; }
    51%, 100% { opacity: 0; }
  }
  .msg .meta {
    font-size: 0.7rem;
    color: var(--text2);
    margin-top: 4px;
  }

  #controls {
    position: fixed;
    bottom: 0;
    width: 100%;
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 16px;
    padding: 20px;
    background: linear-gradient(transparent, var(--bg) 30%);
  }

  .btn {
    width: 72px;
    height: 72px;
    border-radius: 50%;
    border: none;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 28px;
    transition: transform 0.15s, box-shadow 0.15s;
  }
  .btn:hover { transform: scale(1.05); }
  .btn:active { transform: scale(0.95); }

  #micBtn {
    background: var(--accent);
    box-shadow: 0 0 0 0 rgba(233,69,96,0.4);
  }
  #micBtn.recording {
    animation: pulse 1.5s infinite;
    background: #ff2244;
  }
  #micBtn.vad-active {
    background: var(--green);
  }
  #micBtn.vad-active.recording {
    animation: pulse-green 1.5s infinite;
    background: #00ff99;
  }
  @keyframes pulse {
    0% { box-shadow: 0 0 0 0 rgba(233,69,96,0.6); }
    70% { box-shadow: 0 0 0 20px rgba(233,69,96,0); }
    100% { box-shadow: 0 0 0 0 rgba(233,69,96,0); }
  }
  @keyframes pulse-green {
    0% { box-shadow: 0 0 0 0 rgba(0,217,126,0.6); }
    70% { box-shadow: 0 0 0 20px rgba(0,217,126,0); }
    100% { box-shadow: 0 0 0 0 rgba(0,217,126,0); }
  }

  #clearBtn {
    width: 48px; height: 48px;
    background: var(--surface2);
    color: var(--text2);
    font-size: 16px;
  }

  #vadToggle {
    width: 48px; height: 48px;
    background: var(--surface2);
    color: var(--text2);
    font-size: 14px;
  }
  #vadToggle.active {
    background: var(--green);
    color: var(--bg);
  }

  @media (max-width: 480px) {
    .msg { max-width: 92%; }
  }
</style>
</head>
<body>

<header>
  <h1>Friday</h1>
</header>

<div id="status">Connecting...</div>
<div id="chat"></div>

<div id="controls">
  <button class="btn" id="clearBtn" title="Clear conversation">
    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="3 6 5 6 21 6"/><path d="M19 6l-1 14a2 2 0 0 1-2 2H8a2 2 0 0 1-2-2L5 6"/><path d="M10 11v6"/><path d="M14 11v6"/><path d="M9 6V4a1 1 0 0 1 1-1h4a1 1 0 0 1 1 1v2"/></svg>
  </button>
  <button class="btn" id="micBtn" title="Hold to talk (or enable auto-listen)">
    <svg id="micIcon" width="32" height="32" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" y1="19" x2="12" y2="23"/><line x1="8" y1="23" x2="16" y2="23"/></svg>
  </button>
  <button class="btn" id="vadToggle" title="Toggle auto-listen (VAD)">
    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M2 12s3-7 10-7 10 7 10 7-3 7-10 7-10-7-10-7z"/><circle cx="12" cy="12" r="3"/></svg>
  </button>
</div>

<!-- VAD library -->
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/ort.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.19/dist/bundle.min.js"></script>

<script>
const SAMPLE_RATE = 16000;
let ws;
const chatEl = document.getElementById('chat');
const statusEl = document.getElementById('status');
const micBtn = document.getElementById('micBtn');
const clearBtn = document.getElementById('clearBtn');
const vadToggle = document.getElementById('vadToggle');

// ---- State ----
let vadEnabled = false;
let vadInstance = null;
let isProcessing = false;  // Waiting for LLM response
let isSpeaking = false;    // Audio is playing

// ---- Streaming state ----
let streamingMsgEl = null;
let streamingText = '';

// ---- Audio queue for sequential playback ----
const audioQueue = [];
let currentAudio = null;

function enqueueAudio(b64) {
  audioQueue.push(b64);
  playNext();
}

function playNext() {
  if (currentAudio || audioQueue.length === 0) return;

  isSpeaking = true;
  const b64 = audioQueue.shift();
  const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));
  const blob = new Blob([bytes], { type: 'audio/wav' });
  const url = URL.createObjectURL(blob);
  currentAudio = new Audio(url);

  currentAudio.onended = () => {
    URL.revokeObjectURL(url);
    currentAudio = null;
    if (audioQueue.length === 0) {
      isSpeaking = false;
    }
    playNext();
  };

  currentAudio.onerror = () => {
    URL.revokeObjectURL(url);
    currentAudio = null;
    if (audioQueue.length === 0) {
      isSpeaking = false;
    }
    playNext();
  };

  currentAudio.play().catch(() => {
    currentAudio = null;
    if (audioQueue.length === 0) {
      isSpeaking = false;
    }
    playNext();
  });
}

function stopPlayback() {
  // Stop current audio
  if (currentAudio) {
    currentAudio.pause();
    currentAudio.currentTime = 0;
    currentAudio = null;
  }
  // Clear queue
  audioQueue.length = 0;
  isSpeaking = false;
}

function interrupt() {
  console.log('[Interrupt] User interrupted');
  
  // Stop audio playback
  stopPlayback();
  
  // Mark current streaming message as interrupted
  if (streamingMsgEl) {
    streamingMsgEl.classList.remove('streaming');
    streamingMsgEl.classList.add('interrupted');
    streamingMsgEl = null;
    streamingText = '';
  }
  
  // Tell server to cancel
  if (ws && ws.readyState === WebSocket.OPEN) {
    ws.send(JSON.stringify({ type: 'cancel' }));
  }
  
  isProcessing = false;
}

// ---- WebSocket ----
function connect() {
  const proto = location.protocol === 'https:' ? 'wss' : 'ws';
  ws = new WebSocket(`${proto}://${location.host}/ws`);

  ws.onopen = () => setStatus('Loading models... (first time may take a moment)');

  ws.onmessage = (e) => {
    const msg = JSON.parse(e.data);

    if (msg.type === 'ready') {
      updateStatusForMode();
    } else if (msg.type === 'status') {
      setStatus(msg.text, 'active');
    } else if (msg.type === 'transcript') {
      addMessage(msg.role, msg.text, msg.time ? `${msg.time}s` : null);
    } else if (msg.type === 'stream_start') {
      streamingText = '';
      streamingMsgEl = document.createElement('div');
      streamingMsgEl.className = 'msg assistant streaming';
      chatEl.appendChild(streamingMsgEl);
      chatEl.scrollTop = chatEl.scrollHeight;
    } else if (msg.type === 'token') {
      streamingText += msg.text;
      if (streamingMsgEl) {
        streamingMsgEl.textContent = streamingText;
        chatEl.scrollTop = chatEl.scrollHeight;
      }
    } else if (msg.type === 'audio_chunk') {
      enqueueAudio(msg.data);
    } else if (msg.type === 'stream_end') {
      if (streamingMsgEl) {
        streamingMsgEl.classList.remove('streaming');
        streamingMsgEl.textContent = msg.text;

        const t = msg.times;
        const meta = document.createElement('div');
        meta.className = 'meta';
        const parts = [`STT ${t.stt}s`, `LLM ${t.llm}s`, `TTS ${t.tts}s`];
        if (t.first_sentence) {
          parts.push(`first audio ${t.first_sentence}s`);
        }
        meta.textContent = parts.join(' · ');
        streamingMsgEl.appendChild(meta);
        chatEl.scrollTop = chatEl.scrollHeight;
      }
      streamingMsgEl = null;
      streamingText = '';
      isProcessing = false;
      updateStatusForMode();
    } else if (msg.type === 'cancelled') {
      console.log('[WS] Server confirmed cancel');
      isProcessing = false;
      updateStatusForMode();
    } else if (msg.type === 'audio') {
      // Legacy single audio
      playAudio(msg.data);
      const t = msg.times;
      setStatus(`STT ${t.stt}s · LLM ${t.llm}s · TTS ${t.tts}s`, 'active');
      isProcessing = false;
    }
  };

  ws.onclose = () => {
    setStatus('Disconnected. Reconnecting...');
    setTimeout(connect, 2000);
  };
}

// ---- VAD (Voice Activity Detection) ----
async function initVAD() {
  if (vadInstance) return;

  setStatus('Initializing voice detection...', 'active');

  try {
    vadInstance = await vad.MicVAD.new({
      positiveSpeechThreshold: 0.8,
      negativeSpeechThreshold: 0.3,
      minSpeechFrames: 5,
      preSpeechPadFrames: 10,
      redemptionFrames: 15,
      onSpeechStart: () => {
        // If Friday is speaking or processing, interrupt
        if (isSpeaking || isProcessing) {
          interrupt();
        }
        micBtn.classList.add('recording');
        setStatus('Listening...', 'listening');
      },
      onSpeechEnd: (audio) => {
        micBtn.classList.remove('recording');
        if (audio.length > SAMPLE_RATE * 0.3) {
          sendAudio(audio);
        } else {
          updateStatusForMode();
        }
      },
    });
    console.log('[VAD] Initialized');
  } catch (err) {
    console.error('[VAD] Init failed:', err);
    setStatus('VAD init failed: ' + err.message, '');
    vadEnabled = false;
    vadToggle.classList.remove('active');
  }
}

async function startVAD() {
  if (!vadInstance) await initVAD();
  if (vadInstance) {
    vadInstance.start();
    vadEnabled = true;
    vadToggle.classList.add('active');
    micBtn.classList.add('vad-active');
    updateStatusForMode();
    console.log('[VAD] Started');
  }
}

function stopVAD() {
  if (vadInstance) {
    vadInstance.pause();
  }
  vadEnabled = false;
  vadToggle.classList.remove('active');
  micBtn.classList.remove('vad-active');
  micBtn.classList.remove('recording');
  updateStatusForMode();
  console.log('[VAD] Stopped');
}

function toggleVAD() {
  if (vadEnabled) {
    stopVAD();
  } else {
    startVAD();
  }
}

// ---- Send audio to server ----
function sendAudio(float32Audio) {
  const int16 = new Int16Array(float32Audio.length);
  for (let i = 0; i < float32Audio.length; i++) {
    int16[i] = Math.max(-32768, Math.min(32767, Math.round(float32Audio[i] * 32767)));
  }

  const b64 = arrayBufferToBase64(int16.buffer);
  ws.send(JSON.stringify({ type: 'audio', data: b64 }));
  isProcessing = true;
  setStatus('Processing...', 'active');
}

// ---- Manual recording (fallback) ----
let manualChunks = [];
let manualRecorder = null;
let manualStream = null;
let manualCtx = null;

async function startManualRecording() {
  if (vadEnabled) return;

  // Interrupt if speaking
  if (isSpeaking || isProcessing) {
    interrupt();
  }

  if (!manualStream) {
    manualStream = await navigator.mediaDevices.getUserMedia({
      audio: { sampleRate: SAMPLE_RATE, channelCount: 1, echoCancellation: true, noiseSuppression: true }
    });
  }

  manualCtx = new AudioContext({ sampleRate: SAMPLE_RATE });
  const source = manualCtx.createMediaStreamSource(manualStream);
  const proc = manualCtx.createScriptProcessor(4096, 1, 1);

  manualChunks = [];
  proc.onaudioprocess = (e) => {
    const float32 = e.inputBuffer.getChannelData(0);
    manualChunks.push(new Float32Array(float32));
  };

  source.connect(proc);
  proc.connect(manualCtx.destination);
  manualRecorder = { proc, source };

  micBtn.classList.add('recording');
  setStatus('Listening...', 'listening');
}

function stopManualRecording() {
  if (vadEnabled || !manualRecorder) return;

  micBtn.classList.remove('recording');

  const { proc, source } = manualRecorder;
  proc.disconnect();
  source.disconnect();
  manualCtx.close();
  manualRecorder = null;

  const total = manualChunks.reduce((n, c) => n + c.length, 0);
  const merged = new Float32Array(total);
  let offset = 0;
  for (const chunk of manualChunks) {
    merged.set(chunk, offset);
    offset += chunk.length;
  }
  manualChunks = [];

  if (merged.length < SAMPLE_RATE * 0.3) {
    setStatus('Too short — hold longer', 'active');
    return;
  }

  sendAudio(merged);
}

// ---- Audio Playback (legacy) ----
function playAudio(b64) {
  const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));
  const blob = new Blob([bytes], { type: 'audio/wav' });
  const url = URL.createObjectURL(blob);
  const audio = new Audio(url);
  audio.play();
  audio.onended = () => URL.revokeObjectURL(url);
}

// ---- UI helpers ----
function setStatus(text, className = '') {
  statusEl.textContent = text;
  statusEl.className = className;
}

function updateStatusForMode() {
  if (vadEnabled) {
    setStatus('Auto-listen ON — just start talking', 'active');
  } else {
    setStatus('Ready — hold mic or enable auto-listen', 'active');
  }
}

function addMessage(role, text, meta) {
  const div = document.createElement('div');
  div.className = `msg ${role}`;
  div.textContent = text;
  if (meta) {
    const m = document.createElement('div');
    m.className = 'meta';
    m.textContent = meta;
    div.appendChild(m);
  }
  chatEl.appendChild(div);
  chatEl.scrollTop = chatEl.scrollHeight;
}

function arrayBufferToBase64(buffer) {
  const bytes = new Uint8Array(buffer);
  let binary = '';
  for (let i = 0; i < bytes.length; i++) binary += String.fromCharCode(bytes[i]);
  return btoa(binary);
}

// ---- Event handlers ----
micBtn.addEventListener('mousedown', (e) => {
  e.preventDefault();
  startManualRecording();
});
micBtn.addEventListener('mouseup', (e) => {
  e.preventDefault();
  stopManualRecording();
});
micBtn.addEventListener('mouseleave', () => {
  if (manualRecorder) stopManualRecording();
});

micBtn.addEventListener('touchstart', (e) => {
  e.preventDefault();
  startManualRecording();
});
micBtn.addEventListener('touchend', (e) => {
  e.preventDefault();
  stopManualRecording();
});

document.addEventListener('keydown', (e) => {
  if (e.code === 'Space' && !e.repeat && !vadEnabled && !manualRecorder) {
    e.preventDefault();
    startManualRecording();
  }
});
document.addEventListener('keyup', (e) => {
  if (e.code === 'Space' && manualRecorder) {
    e.preventDefault();
    stopManualRecording();
  }
});

vadToggle.addEventListener('click', toggleVAD);

clearBtn.addEventListener('click', () => {
  chatEl.innerHTML = '';
  stopPlayback();
  ws.send(JSON.stringify({ type: 'clear' }));
});

// ---- Init ----
connect();
</script>
</body>
</html>
